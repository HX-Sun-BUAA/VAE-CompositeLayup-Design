{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adfeb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Function to check conditions for the ply layer, input shape is (1, 65)\n",
    "def check_conditions(random_data):\n",
    "    row_angles = random_data[random_data != -90]\n",
    "    ply = row_angles[:-1]\n",
    "    if row_angles[-1] == 1:\n",
    "        symmetric_ply = np.concatenate((ply, ply[::-1]))\n",
    "    else:\n",
    "        ply_trimmed = ply[:-1]\n",
    "        symmetric_ply = np.concatenate((ply, ply_trimmed[::-1]))\n",
    "        \n",
    "    length = len(symmetric_ply)\n",
    "    if length == 0:\n",
    "        return 1, 0, 45\n",
    "    else:\n",
    "        contiguity_constraint = adjacent_angle_index = 0\n",
    "        gathering_index = 2\n",
    "\n",
    "        # Evaluate ply layer gathering\n",
    "        gathering_index_judge = np.random.randint(2,6)\n",
    "        \n",
    "        for j in range(2,7):\n",
    "            for i in range(length+1-j):\n",
    "                if len(set(symmetric_ply[i:i+j])) == 1:\n",
    "                    gathering_index = j\n",
    "                    if gathering_index > gathering_index_judge:\n",
    "                        contiguity_constraint = 1\n",
    "\n",
    "        adjacent_angles = [0]\n",
    "        for k in range(1, len(ply)):\n",
    "            prev_value = ply[k - 1]\n",
    "            value = ply[k]\n",
    "            adjacent_angle = min(abs(prev_value - value), 180-abs(prev_value - value))\n",
    "            adjacent_angles.append(adjacent_angle)\n",
    "\n",
    "        adjacent_angle_index = max(max(adjacent_angles),45)\n",
    "\n",
    "        return contiguity_constraint, gathering_index, adjacent_angle_index\n",
    "\n",
    "# Calculate Laminate Parameters, input shape is (1, 65)\n",
    "def LaminateParameters(random_data):\n",
    "    row_angles = random_data[random_data != -90]\n",
    "    ply = row_angles[:-1]\n",
    "    if row_angles[-1] == 1:\n",
    "        symmetric_ply = np.concatenate((ply, ply[::-1]))\n",
    "    else:\n",
    "        ply_trimmed = ply[:-1]\n",
    "        symmetric_ply = np.concatenate((ply, ply_trimmed[::-1]))\n",
    "        \n",
    "    n = len(symmetric_ply)\n",
    "    \n",
    "    if n == 0:\n",
    "        return [-1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
    "    else:\n",
    "        angles_radians = torch.deg2rad(torch.Tensor(symmetric_ply))\n",
    "\n",
    "        # Calculate z(i)\n",
    "        layer_heights = (torch.cumsum(torch.ones(n), dim=0)-n/2)\n",
    "\n",
    "        # Calculate a1,a2,a3,a4\n",
    "        a1 = round(1/n * torch.sum(torch.cos(2 * angles_radians) * (layer_heights - (layer_heights - 1))).item(), 4)\n",
    "        a2 = round(1/n * torch.sum(torch.cos(4 * angles_radians) * (layer_heights - (layer_heights - 1))).item(), 4)\n",
    "        a3 = round(1/n * torch.sum(torch.sin(2 * angles_radians) * (layer_heights - (layer_heights - 1))).item(), 4)\n",
    "        a4 = round(1/n * torch.sum(torch.sin(4 * angles_radians) * (layer_heights - (layer_heights - 1))).item(), 4)\n",
    "\n",
    "        # Calculate d1,d2,d3,d4\n",
    "        d1 = round(4/(n**3) * torch.sum(torch.cos(2 * angles_radians) * (layer_heights**3 - (layer_heights - 1)**3)).item(), 4)\n",
    "        d2 = round(4/(n**3) * torch.sum(torch.cos(4 * angles_radians) * (layer_heights**3 - (layer_heights - 1)**3)).item(), 4)\n",
    "        d3 = round(4/(n**3) * torch.sum(torch.sin(2 * angles_radians) * (layer_heights**3 - (layer_heights - 1)**3)).item(), 4)\n",
    "        d4 = round(4/(n**3) * torch.sum(torch.sin(4 * angles_radians) * (layer_heights**3 - (layer_heights - 1)**3)).item(), 4)\n",
    "\n",
    "        return [a1, a2, a3, a4, d1, d2, d3, d4, n]\n",
    "\n",
    "# Encode ply angles into binary representation\n",
    "angle_mapping = {\n",
    "    0: '1000000000000', -15: '0100000000000', -30: '0010000000000', -45: '0001000000000', -60: '0000100000000',\n",
    "    -75: '0000010000000', -90: '0000001000000', 90: '0000000100000', 75: '0000000010000', 60: '0000000001000',\n",
    "    45: '0000000000100', 30: '0000000000010', 15: '0000000000001',\n",
    "}\n",
    "\n",
    "def normalize_data(tensor, min_vals, max_vals):\n",
    "    \"\"\"\n",
    "    Normalize each column of the tensor to the range [0, 1].\n",
    "    Each column is treated independently.\n",
    "    \"\"\"\n",
    "    # Normalize each column independently\n",
    "    normalized_tensor = (tensor - min_vals) / (max_vals - min_vals)\n",
    "\n",
    "    return normalized_tensor\n",
    "\n",
    "loaded_ply_angle = torch.load('0304ply_angle.pt')\n",
    "\n",
    "def batch_encode_angles(angles_batch):\n",
    "    batch_size = angles_batch.shape[0]\n",
    "    num_angles = angles_batch.shape[1] - 1  # The last column is not included in the encoding\n",
    "    encoded_result = np.zeros((batch_size, num_angles * 13 + 1), dtype=int)  # 13 bits for each angle\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        for i in range(num_angles):\n",
    "            angle = angles_batch[batch_idx, i]\n",
    "            angle_key = angle_mapping.get(angle)\n",
    "\n",
    "            # Convert to 13-bit binary code\n",
    "            encoded_bits = [int(bit) for bit in angle_key]\n",
    "            encoded_result[batch_idx, i * 13:(i + 1) * 13] = encoded_bits\n",
    "        \n",
    "        # Add the value of the last column to the last column of the encoding result\n",
    "        encoded_result[batch_idx, -1] = angles_batch[batch_idx, -1]\n",
    "\n",
    "    return torch.tensor(encoded_result)\n",
    "\n",
    "loaded_ply_01encoded = batch_encode_angles(loaded_ply_angle.numpy())\n",
    "loaded_ply_01encoded = torch.tensor(loaded_ply_01encoded)\n",
    "\n",
    "loaded_normalized_LP_tensor = torch.load('0304normalized_LP_tensor.pt')\n",
    "loaded_normalized_Index_tensor = torch.load('0304normalized_Index_tensor.pt')\n",
    "loaded_Index_tensor = torch.load('0304Index_tensor.pt')\n",
    "loaded_LP_tensor = torch.load('0304LP_tensor.pt')\n",
    "\n",
    "index_min_vals = torch.min(loaded_Index_tensor, dim=0)[0]\n",
    "index_max_vals = torch.max(loaded_Index_tensor, dim=0)[0]\n",
    "\n",
    "LP_min_vals = torch.min(loaded_LP_tensor, dim=0)[0]\n",
    "LP_max_vals = torch.max(loaded_LP_tensor, dim=0)[0]\n",
    "\n",
    "# Dataset and DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, ply_angle, ply_01encoded, normalized_LP_tensor, normalized_Index_tensor):\n",
    "        self.ply_angle = ply_angle\n",
    "        self.ply_01encoded = ply_01encoded\n",
    "        self.normalized_LP_tensor = normalized_LP_tensor\n",
    "        self.normalized_Index_tensor = normalized_Index_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ply_01encoded)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_point = {\n",
    "            \"Ply_angle\": self.ply_angle[index],\n",
    "            \"Input01\": self.ply_01encoded[index],\n",
    "            \"Norm_LP\": self.normalized_LP_tensor[index],\n",
    "            \"Norm_index\": self.normalized_Index_tensor[index],\n",
    "        }\n",
    "        return data_point\n",
    "\n",
    "# Dataloaders for training, validation, and testing\n",
    "batch_size = 50\n",
    "train_loader = DataLoader(\n",
    "    dataset=CustomDataset(loaded_ply_angle[0:35000], loaded_ply_01encoded[0:35000], loaded_normalized_LP_tensor[0:35000], loaded_normalized_Index_tensor[0:35000]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "vali_loader = DataLoader(\n",
    "    dataset=CustomDataset(loaded_ply_angle[35000:45000], loaded_ply_01encoded[35000:45000], loaded_normalized_LP_tensor[35000:45000], loaded_normalized_Index_tensor[35000:45000]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=CustomDataset(loaded_ply_angle[45000:50000], loaded_ply_01encoded[45000:50000], loaded_normalized_LP_tensor[45000:50000], loaded_normalized_Index_tensor[45000:50000]),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "    \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Function to compute accuracy of the autoencoder by comparing input and output\n",
    "def accuracy(data1, data2):\n",
    "    total_elements = torch.numel(data1)\n",
    "    diff = torch.abs(data1 - data2)\n",
    "    accuracy = torch.sum(diff == 0) / total_elements\n",
    "    return accuracy.item()\n",
    "\n",
    "# Function to decode ply angles from the binary representation\n",
    "angle_docode_mapping = {\n",
    "    '1000000000000':0, '0100000000000':-15, '0010000000000':-30, '0001000000000':-45, '0000100000000':-60,\n",
    "    '0000010000000':-75, '0000001000000':-90, '0000000100000':90, '0000000010000':75, '0000000001000':60,\n",
    "    '0000000000100':45, '0000000000010':30, '0000000000001':15,\n",
    "}\n",
    "\n",
    "def decode_angles(encoded_angles):\n",
    "    num_angles = 64\n",
    "    decoded_angles = np.zeros((encoded_angles.shape[0], num_angles), dtype=int)\n",
    "\n",
    "    for i in range(encoded_angles.shape[0]):\n",
    "        for j in range(num_angles):\n",
    "            start_idx = j * 13\n",
    "            end_idx = (j + 1) * 13\n",
    "            angle_key = ''.join(str(bit) for bit in encoded_angles[i, start_idx:end_idx].astype(int))\n",
    "            decoded_angles[i, j] = angle_docode_mapping.get(angle_key, -90)\n",
    "            \n",
    "    return np.concatenate((decoded_angles, encoded_angles[:,-1].reshape(-1,1)), axis=1)\n",
    "\n",
    "# Plot two ply layer arrays for comparison\n",
    "def plot_two_ply(array1, array2, save=False, filename='my_plot.png'):\n",
    "    angle_array1 = array1[:-1]\n",
    "    transposed_array1 = angle_array1.reshape(64, 13).T\n",
    "    sym_column1 = np.full((13, 1), array1[-1])\n",
    "    ply1 = np.concatenate((transposed_array1, sym_column1), axis=1)\n",
    "    \n",
    "    angle_array2 = array2[:-1]\n",
    "    transposed_array2 = angle_array2.reshape(64, 13).T\n",
    "    sym_column2 = np.full((13, 1), array2[-1])\n",
    "    ply2 = np.concatenate((transposed_array2, sym_column2), axis=1)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 1))  # 1 row, 2 columns\n",
    "\n",
    "    # Create a custom colormap that goes from white to dark gray\n",
    "    colors = [(222/255.0, 239/255.0, 251/255.0), (180/255.0, 210/255.0, 217/255.0), (50/255.0, 97/255.0, 115/255.0), (3/255.0, 23/255.0, 64/255.0), (1/255.0, 14/255.0, 38/255.0)]\n",
    "    cmap_name = 'my_colormap'\n",
    "    cm = mcolors.LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "\n",
    "    # Plot the first array with the custom colormap and add the grid\n",
    "    axs[0].imshow(ply1, cmap=cm, aspect='auto', origin='lower')\n",
    "    axs[0].grid(True)\n",
    "    axs[0].set_xticks([])\n",
    "    axs[0].set_yticks([])\n",
    "\n",
    "    # Plot the second array with the custom colormap and add the grid\n",
    "    im = axs[1].imshow(ply2, cmap=cm, aspect='auto', origin='lower')\n",
    "    axs[1].grid(True)\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yticks([])\n",
    "    \n",
    "    cbar = fig.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04, ticks=[0, 1])\n",
    "    cbar.ax.set_yticklabels(['0', '1'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig(filename, dpi=900)  # Save the image\n",
    "    plt.show()\n",
    "    \n",
    "def plot_two_arrays(array1, array2):\n",
    "    assert array1.ndim == 1 and array2.ndim == 1, \"Both arrays must be 1-D.\"\n",
    "    \n",
    "    x_axis = np.arange(max(len(array1), len(array2)))\n",
    "    plt.figure(figsize=(10, 1))\n",
    "    plt.plot(x_axis[:len(array1)], array1, color='red', label='Input', linewidth=0.5, alpha=0.8)\n",
    "    plt.plot(x_axis[:len(array2)], array2, color='blue', label='Output', linewidth=0.5, alpha=0.8)\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.show()\n",
    "\n",
    "# Define the Encoder module\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, seq_length, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=13, stride=13, padding=0)\n",
    "        self.bn1 = nn.BatchNorm1d(16)  \n",
    "        \n",
    "        self.conv2_1 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=2, stride=1, padding=0)\n",
    "        self.bn2_1 = nn.BatchNorm1d(8)\n",
    "        \n",
    "        self.conv2_3 = nn.Conv1d(in_channels=16, out_channels=8, kernel_size=4, stride=1, padding=2)\n",
    "        self.bn2_3 = nn.BatchNorm1d(8)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1025, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(1025, 256)\n",
    "        self.bn4 = nn.BatchNorm1d(256)\n",
    "        self.fc_mean = nn.Linear(512, z_dim)\n",
    "        self.fc_logvar = nn.Linear(512, z_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_angle = x[:, :832].unsqueeze(1)\n",
    "        x_sym = x[:, 832].unsqueeze(1)\n",
    "        \n",
    "        xconv1 = self.dropout(F.relu(self.bn1(self.conv1(x_angle))))        #torch.Size([50, 16, 64])\n",
    "        xconv2_1 = self.dropout(F.relu(self.bn2_1(self.conv2_1(xconv1))))  #torch.Size([50, 8, 63])\n",
    "        xconv2_3 = self.dropout(F.relu(self.bn2_3(self.conv2_3(xconv1))))  #torch.Size([50, 8, 65]) \n",
    "        xconv2 = torch.cat((xconv2_1, xconv2_3), dim=2)                    #torch.Size([50, 8, 128]) \n",
    "        \n",
    "        xflattenconv1 = self.flatten(xconv1)                               #torch.Size([50, 16*64]) \n",
    "        xflattenconv2 = self.flatten(xconv2)                               #torch.Size([50, 8*128]) \n",
    "        x1 = torch.cat((xflattenconv1, x_sym), dim=1)                      #torch.Size([50, 1025])\n",
    "        x2 = torch.cat((xflattenconv2, x_sym), dim=1)                      #torch.Size([50, 1025])\n",
    "        xfc1 =  F.relu(self.bn3(self.fc1(x1)))                             #torch.Size([50, 256])\n",
    "        xfc2 =  F.relu(self.bn4(self.fc2(x2)))                             #torch.Size([50, 256])\n",
    "        xfc = torch.cat((xfc1, xfc2), dim=1)                               #torch.Size([50, 512])\n",
    "        mean = self.fc_mean(xfc)                                           #torch.Size([50, z_dim])\n",
    "        mean[:, :9] = torch.sigmoid(mean[:, :9])\n",
    "        logvar = self.fc_logvar(xfc)                                       #torch.Size([50, z_dim])\n",
    "        return mean, logvar\n",
    "\n",
    "# Define the Decoder module\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seq_length, z_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.deconv1 = nn.ConvTranspose1d(in_channels=16, out_channels=4, kernel_size=13, stride=13, padding=0)\n",
    "        self.bn_deconv1 = nn.BatchNorm1d(4)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(52*64, 176)\n",
    "        self.bn2 = nn.BatchNorm1d(176)\n",
    "        \n",
    "        self.fc3 = nn.Linear(1200, seq_length)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        xfc1 = self.dropout(F.relu(self.bn1(self.fc1(x))))                             #torch.Size([50, 1024])\n",
    "        xfc1_reshape = xfc1.view(xfc1.size(0), 16, 64)                                 #torch.Size([50, 16, 64])\n",
    "        \n",
    "        xdeconv1 = self.dropout(F.relu(self.bn_deconv1(self.deconv1(xfc1_reshape))))   #torch.Size([50, 4, 64*13])\n",
    "        xflatten_deconv1 = self.flatten(xdeconv1)                                      #torch.Size([50, 4*64*13])\n",
    "        xfc2 = self.dropout(F.relu(self.bn2(self.fc2(xflatten_deconv1))))              #torch.Size([50, 176])\n",
    "        \n",
    "        x_cat = torch.cat((xfc1, xfc2), dim=1)                                         #torch.Size([50, 1200])\n",
    "        x = self.fc3(x_cat)\n",
    "        x1 = x[:,:832].view(x.size(0), 64, 13)\n",
    "        x1 = self.softmax(x1)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "        x2 = self.sigmoid(x[:,832].unsqueeze(1))\n",
    "        x = torch.cat((x1,x2), dim=1)\n",
    "        return x\n",
    "\n",
    "# Define the VAE module\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, seq_length, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(seq_length, z_dim)\n",
    "        self.decoder = Decoder(seq_length, z_dim)\n",
    "\n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar[:, 9:])\n",
    "        eps = torch.randn_like(std)\n",
    "        mean[:, 9:] += eps * std\n",
    "        return mean\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, mean, logvar\n",
    "\n",
    "seq_length = 833\n",
    "z_dim = 128\n",
    "vae_model = VAE(seq_length, z_dim)\n",
    "\n",
    "# Define hybrid loss function (MAE + MRE)\n",
    "def hybrid_loss(y_true, y_pred, alpha=0.9, epsilon=0.01):\n",
    "    mae = F.l1_loss(y_true, y_pred)\n",
    "    mre = torch.mean(torch.abs((y_true - y_pred) / (torch.abs(y_true) + epsilon)))\n",
    "    return alpha * mae + (1 - alpha) * mre\n",
    "\n",
    "def vae_loss(x_recon, x, mean, logvar, norm_prop, norm_index):\n",
    "    beta0, beta1, beta2 = 0.3, 0.2, 5000\n",
    "    recon_loss = F.binary_cross_entropy(x_recon, x, reduction='sum')\n",
    "    kld_loss = -0.5 * torch.sum(1 + logvar[:,9:] - mean[:,9:].pow(2) - logvar[:,9:].exp())\n",
    "    reg_loss1 = (F.mse_loss(mean[:,:6], norm_prop[:,:6]) + F.mse_loss(mean[:,6], norm_prop[:,6]))*5\n",
    "    reg_loss2 = F.mse_loss(mean[:,7:9], norm_index)\n",
    "    return beta0 * recon_loss, beta1 * kld_loss, beta2 * (reg_loss1 + reg_loss2)\n",
    "\n",
    "# Training setup\n",
    "optimizer = optim.Adam(vae_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, threshold=0.1, verbose=True, min_lr=1e-12)\n",
    "\n",
    "# Define variables to track training and validation losses\n",
    "train_losses = []\n",
    "recon_losses = []\n",
    "kld_losses = []\n",
    "reg_losses = []\n",
    "noise_losses = []\n",
    "vali_losses = []\n",
    "vali_recon_losses = []\n",
    "vali_kld_losses = []\n",
    "vali_reg_losses = []\n",
    "vali_noise_losses = []\n",
    "num_epochs = 500\n",
    "validate_every = 5  # Validate every 5 epochs\n",
    "\n",
    "# Start training timer\n",
    "start_time = time.time()\n",
    "print(\"Start Training! Time:\", time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time)))\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    vae_model.train()\n",
    "    loss_train = loss_recon = loss_kld = loss_reg = loss_noise = 0.0\n",
    "    tp, acc = 0, 0 # For tracking training progress and accuracy\n",
    "\n",
    "    for batch in train_loader:\n",
    "        raw_data_batch = batch[\"Input01\"].to(torch.float32)\n",
    "        norm_LP_batch = batch[\"Norm_LP\"].to(torch.float32)\n",
    "        norm_index_batch = batch[\"Norm_index\"].to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mean, logvar = vae_model(raw_data_batch)\n",
    "        recon_loss, kld_loss, reg_loss = vae_loss(recon_batch, raw_data_batch, mean, logvar, norm_LP_batch, norm_index_batch)\n",
    "        \n",
    "        hidden_with_noise = mean.clone()\n",
    "        hidden_with_noise[:, 9:] = torch.randn_like(hidden_with_noise[:, 9:])\n",
    "        recon_with_noise = vae_model.decoder(hidden_with_noise)\n",
    "        recon_with_noise_angle = np.eye(13)[np.argmax(recon_with_noise[:,:832].detach().cpu().numpy().reshape(-1,64,13), axis = 2)].reshape(-1,64*13)\n",
    "        decoded_recon_with_noise = decode_angles(np.concatenate((recon_with_noise_angle,recon_with_noise[:,-1].detach().cpu().numpy().round().reshape(-1,1)), axis=1))    \n",
    "        noise_loss = 0\n",
    "        \n",
    "        for j in range(len(decoded_recon_with_noise)):\n",
    "            row_angles = decoded_recon_with_noise[j].reshape(1,-1)\n",
    "            if row_angles.size == 0:\n",
    "                row_angles = np.resize(row_angles, (1, 1))\n",
    "            LP = LaminateParameters(row_angles)\n",
    "            recon_LP = torch.Tensor(LP[0:3] + LP[4:7] + [LP[8]])\n",
    "            normalized_recon_LP = normalize_data(recon_LP, LP_min_vals, LP_max_vals)\n",
    "            noise_loss += (F.mse_loss(normalized_recon_LP[:6], hidden_with_noise[j, :6])+F.mse_loss(normalized_recon_LP[-1], hidden_with_noise[j, 6]))*300\n",
    "            \n",
    "            contiguity_constraint, gathering_index, adjacent_angle_index = check_conditions(row_angles)\n",
    "            recon_index = torch.Tensor([gathering_index, adjacent_angle_index])\n",
    "            normalized_recon_index = normalize_data(recon_index, index_min_vals, index_max_vals)\n",
    "            noise_loss += F.mse_loss(hidden_with_noise[j, 7:9], normalized_recon_index)*30\n",
    "                            \n",
    "        train_loss = recon_loss + kld_loss + reg_loss + noise_loss\n",
    "        \n",
    "        train_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(vae_model.parameters(), max_norm=20.0)\n",
    "        optimizer.step()\n",
    "        loss_train += train_loss.item()\n",
    "        loss_recon += recon_loss.item()\n",
    "        loss_kld += kld_loss.item()\n",
    "        loss_reg += reg_loss.item()\n",
    "        loss_noise += noise_loss.item()\n",
    "    \n",
    "    if (epoch + 1) % validate_every == 0:\n",
    "        vae_model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_vali = loss_recon_vali = loss_kld_vali = loss_reg_vali = loss_noise_vali = 0.0\n",
    "\n",
    "            for batch in vali_loader:\n",
    "                raw_data_vali_batch = batch[\"Input01\"].to(torch.float32)\n",
    "                norm_LP_batch_vali = batch[\"Norm_LP\"].to(torch.float32)\n",
    "                norm_index_batch_vali = batch[\"Norm_index\"].to(torch.float32)\n",
    "                ply_angle_vali_batch = batch[\"Ply_angle\"].to(torch.float32)\n",
    "                \n",
    "                recon_vali_batch, mean_vali, logvar_vali = vae_model(raw_data_vali_batch)\n",
    "                recon_loss_vali, kld_loss_vali, reg_loss_vali = vae_loss(recon_vali_batch, raw_data_vali_batch, mean_vali, logvar_vali, norm_LP_batch_vali, norm_index_batch_vali)\n",
    "                recon_vali_batch_angle = np.eye(13)[np.argmax(recon_vali_batch[:,:832].detach().cpu().numpy().reshape(-1,64,13), axis = 2)].reshape(-1,64*13)\n",
    "                decoded_recon_vali_batch = decode_angles(np.concatenate((recon_vali_batch_angle,recon_vali_batch[:,-1].detach().cpu().numpy().reshape(-1,1)), axis=1))\n",
    "                \n",
    "                acc += accuracy(ply_angle_vali_batch, decoded_recon_vali_batch)\n",
    "                \n",
    "                hidden_with_noise = mean_vali.clone()\n",
    "                hidden_with_noise[:, 9:] = torch.randn_like(hidden_with_noise[:, 9:])\n",
    "                recon_with_noise = vae_model.decoder(hidden_with_noise)\n",
    "                recon_with_noise_angle = np.eye(13)[np.argmax(recon_with_noise[:,:832].detach().cpu().numpy().reshape(-1,64,13), axis = 2)].reshape(-1,64*13)\n",
    "                decoded_recon_with_noise = decode_angles(np.concatenate((recon_with_noise_angle,recon_with_noise[:,-1].detach().cpu().numpy().round().reshape(-1,1)), axis=1))    \n",
    "                noise_loss_vali = 0\n",
    "                \n",
    "                for j in range(len(decoded_recon_with_noise)):\n",
    "                    row_angles = decoded_recon_with_noise[j].reshape(1,-1)\n",
    "                    if row_angles.size == 0:\n",
    "                        row_angles = np.resize(row_angles, (1, 1))\n",
    "                    LP = LaminateParameters(row_angles)\n",
    "                    recon_LP = torch.Tensor(LP[0:3] + LP[4:7] + [LP[8]])\n",
    "                    normalized_recon_LP = normalize_data(recon_LP, LP_min_vals, LP_max_vals)\n",
    "                    noise_loss_vali += (F.mse_loss(normalized_recon_LP[:6], hidden_with_noise[j, :6])+F.mse_loss(normalized_recon_LP[-1], hidden_with_noise[j, 6]))*300\n",
    "                    \n",
    "                    contiguity_constraint, gathering_index, adjacent_angle_index = check_conditions(row_angles)\n",
    "                    recon_index = torch.Tensor([gathering_index, adjacent_angle_index])\n",
    "                    normalized_recon_index = normalize_data(recon_index, index_min_vals, index_max_vals)\n",
    "                    noise_loss_vali += F.mse_loss(hidden_with_noise[j, 7:9], normalized_recon_index)*30\n",
    "                    \n",
    "                loss_vali += recon_loss_vali + kld_loss_vali + reg_loss_vali + noise_loss_vali\n",
    "                loss_recon_vali += recon_loss_vali\n",
    "                loss_kld_vali += kld_loss_vali\n",
    "                loss_reg_vali += reg_loss_vali\n",
    "                loss_noise_vali += noise_loss_vali\n",
    "\n",
    "            vali_losses.append(loss_vali / len(vali_loader.dataset))\n",
    "            vali_recon_losses.append(loss_recon_vali / len(vali_loader.dataset))\n",
    "            vali_kld_losses.append(loss_kld_vali / len(vali_loader.dataset))\n",
    "            vali_reg_losses.append(loss_reg_vali / len(vali_loader.dataset))\n",
    "            vali_noise_losses.append(loss_noise_vali / len(vali_loader.dataset))\n",
    "            \n",
    "            acc /= (len(vali_loader.dataset)/batch_size)\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}] Validation Loss: {loss_vali / len(vali_loader.dataset):.4f}, \"\n",
    "                  f\"Recon Loss: {loss_recon_vali / len(vali_loader.dataset):.4f}, \"\n",
    "                  f\"KLD Loss: {loss_kld_vali / len(vali_loader.dataset):.4f}, \"\n",
    "                  f\"Reg Loss: {loss_reg_vali / len(vali_loader.dataset):.4f}, \"\n",
    "                  f\"Noise Loss: {loss_noise_vali / len(vali_loader.dataset):.4f}\")\n",
    "\n",
    "            # Adjust learning rate based on validation loss\n",
    "            scheduler.step(loss_vali / len(vali_loader.dataset))\n",
    "    \n",
    "    train_losses.append(loss_train / len(train_loader.dataset))\n",
    "    recon_losses.append(loss_recon / len(train_loader.dataset))\n",
    "    kld_losses.append(loss_kld / len(train_loader.dataset))\n",
    "    reg_losses.append(loss_reg / len(train_loader.dataset))\n",
    "    noise_losses.append(loss_noise / len(train_loader.dataset))\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {loss_train / len(train_loader.dataset):.4f} \"\n",
    "          f\"- Recon Loss: {loss_recon / len(train_loader.dataset):.4f} - KLD Loss: {loss_kld / len(train_loader.dataset):.4f} - Reg Loss: {loss_reg / len(train_loader.dataset):.4f}- Noise Loss: {loss_noise / len(train_loader.dataset):.4f}\")\n",
    "\n",
    "# End training timer\n",
    "end_time = time.time()\n",
    "print(\"Training completed!\")\n",
    "print(f\"Training duration: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), recon_losses, label='Train Recon Loss')\n",
    "plt.plot(range(1, num_epochs + 1), kld_losses, label='Train KLD Loss')\n",
    "plt.plot(range(1, num_epochs + 1), reg_losses, label='Train Reg Loss')\n",
    "plt.plot(range(1, num_epochs + 1), noise_losses, label='Train Noise Loss')\n",
    "plt.plot(range(validate_every, num_epochs + 1, validate_every), vali_losses, label='Vali Loss')\n",
    "plt.plot(range(validate_every, num_epochs + 1, validate_every), vali_recon_losses, label='Vali Recon Loss')\n",
    "plt.plot(range(validate_every, num_epochs + 1, validate_every), vali_kld_losses, label='Vali KLD Loss')\n",
    "plt.plot(range(validate_every, num_epochs + 1, validate_every), vali_reg_losses, label='Vali Reg Loss')\n",
    "plt.plot(range(validate_every, num_epochs + 1, validate_every), vali_noise_losses, label='Vali Noise Loss')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Losses vs. Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "torch.save(vae_model.state_dict(), '0304vae_model.pth')\n",
    "\n",
    "state_dict = torch.load('0304vae_model.pth')\n",
    "vae_model.load_state_dict(state_dict)\n",
    "\n",
    "# Design function to generate random designs based on fixed and random components\n",
    "def Design(fixed_components, random_components, num_total, random_G, random_A):\n",
    "    with torch.no_grad():  \n",
    "        fixed_components_repeated = fixed_components.repeat(num_total, 1)\n",
    "        if fixed_components[-1] == -1: fixed_components_repeated[:, -1] = random_A.view(-1)\n",
    "        if fixed_components[-2] == -1: fixed_components_repeated[:, -2] = random_G.view(-1)\n",
    "        hidden_with_noise = torch.cat((fixed_components_repeated, random_components), dim=1)\n",
    "        recon_with_noise = vae_model.decoder(hidden_with_noise)\n",
    "        recon_with_noise_angle = np.eye(13)[np.argmax(recon_with_noise[:,:832].detach().cpu().numpy().reshape(-1,64,13), axis = 2)].reshape(-1,64*13)\n",
    "        decoded_recon_with_noise = decode_angles(np.concatenate((recon_with_noise_angle,recon_with_noise[:,-1].detach().cpu().numpy().round().reshape(-1,1)), axis=1))    \n",
    "        \n",
    "    return decoded_recon_with_noise\n",
    "\n",
    "def denormalize_data(normalized_tensor, min_vals, max_vals):\n",
    "    denormalized_tensor = normalized_tensor * (max_vals - min_vals) + min_vals\n",
    "    return denormalized_tensor\n",
    "\n",
    "# Example of how to call VAE to achieve design for 100-ply laminate\n",
    "\n",
    "# Normalize target laminate parameters\n",
    "target_LP = torch.Tensor([0, 0, 0, 0, 0, 0, 100])\n",
    "norm_target_LP = normalize_data(target_LP, LP_min_vals, LP_max_vals)\n",
    "fixed_components = torch.cat((norm_target_LP,torch.Tensor([-1,-1])))\n",
    "\n",
    "# Generate random components for design\n",
    "num_total = 100000\n",
    "random_components = torch.randn(num_total, z_dim-9)\n",
    "random_A = torch.randint(0, 4, size=(num_total, 1)).float() / 3\n",
    "random_G = torch.randint(0, 4, size=(num_total, 1)).float() / 3\n",
    "\n",
    "# Start timing\n",
    "start_time = time.time()\n",
    "start_time_readable = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(start_time))\n",
    "print(\"Start Solving! Start Time:\", start_time_readable)\n",
    "\n",
    "design = Design(fixed_components, random_components, num_total, random_G, random_A)\n",
    "end_time = time.time()  # End timing\n",
    "print(\"Design solving time:\", end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
